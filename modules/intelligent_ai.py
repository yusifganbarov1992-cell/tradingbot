"""
Intelligent AI Module - Phase 7
Multi-model ensemble –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã

–í–∫–ª—é—á–∞–µ—Ç:
1. LSTM - –¥–ª—è time series prediction
2. Technical Pattern Recognition - –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö
3. Ensemble Voting - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
4. Integration —Å Adaptive Learning (Phase 4)
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from enum import Enum
import json
import pickle
from pathlib import Path

# Deep Learning
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# ML
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split

logger = logging.getLogger(__name__)


class PredictionSignal(Enum):
    """–°–∏–≥–Ω–∞–ª—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    STRONG_BUY = "STRONG_BUY"      # –í—Å–µ –º–æ–¥–µ–ª–∏ –≥–æ–≤–æ—Ä—è—Ç BUY
    BUY = "BUY"                    # –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –≥–æ–≤–æ—Ä–∏—Ç BUY
    NEUTRAL = "NEUTRAL"            # –ù–µ—Ç consensus
    SELL = "SELL"                  # –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –≥–æ–≤–æ—Ä–∏—Ç SELL
    STRONG_SELL = "STRONG_SELL"    # –í—Å–µ –º–æ–¥–µ–ª–∏ –≥–æ–≤–æ—Ä—è—Ç SELL


class TimeSeriesDataset(Dataset):
    """Dataset –¥–ª—è LSTM"""
    
    def __init__(self, data: np.ndarray, labels: np.ndarray):
        self.data = torch.FloatTensor(data)
        self.labels = torch.FloatTensor(labels)
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]


class LSTMPricePredictor(nn.Module):
    """
    LSTM –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã
    
    Architecture:
    - Input: (sequence_length, features)
    - LSTM layers: 2 —Å–ª–æ—è —Å dropout
    - Output: 1 (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã)
    """
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.2):
        super(LSTMPricePredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM layers
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # Fully connected layers
        self.fc1 = nn.Linear(hidden_size, 64)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout)
        self.fc2 = nn.Linear(64, 1)
    
    def forward(self, x):
        # LSTM
        lstm_out, _ = self.lstm(x)
        
        # Take last output
        last_output = lstm_out[:, -1, :]
        
        # Fully connected
        out = self.fc1(last_output)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out


class PatternRecognizer:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö
    
    –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
    - Head and Shoulders (–ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏)
    - Double Top/Bottom (–î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞/–¥–Ω–æ)
    - Triangle (–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫)
    - Flag/Pennant (–§–ª–∞–≥/–í—ã–º–ø–µ–ª)
    - Support/Resistance breakout
    """
    
    def __init__(self):
        self.patterns = {
            'head_shoulders': 0,
            'double_top': 0,
            'double_bottom': 0,
            'ascending_triangle': 0,
            'descending_triangle': 0,
            'flag': 0,
            'pennant': 0,
            'support_breakout': 0,
            'resistance_breakout': 0
        }
    
    def detect_patterns(self, df: pd.DataFrame) -> Dict:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            Dict —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –∏ –∏—Ö —Å–∏–≥–Ω–∞–ª–∞–º–∏
        """
        if len(df) < 50:
            return {'error': 'Not enough data for pattern recognition'}
        
        results = {}
        
        # Head and Shoulders
        hs_signal = self._detect_head_shoulders(df)
        if hs_signal:
            results['head_shoulders'] = hs_signal
        
        # Double Top/Bottom
        dt_signal = self._detect_double_top(df)
        if dt_signal:
            results['double_top'] = dt_signal
        
        db_signal = self._detect_double_bottom(df)
        if db_signal:
            results['double_bottom'] = db_signal
        
        # Triangles
        at_signal = self._detect_ascending_triangle(df)
        if at_signal:
            results['ascending_triangle'] = at_signal
        
        dt_signal = self._detect_descending_triangle(df)
        if dt_signal:
            results['descending_triangle'] = dt_signal
        
        # Support/Resistance breakout
        sr_signal = self._detect_support_resistance_breakout(df)
        if sr_signal:
            results['breakout'] = sr_signal
        
        return results
    
    def _detect_head_shoulders(self, df: pd.DataFrame) -> Optional[Dict]:
        """–ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏ (bearish pattern)"""
        if len(df) < 50:
            return None
        
        highs = df['high'].values[-50:]
        
        # –ü—Ä–æ—Å—Ç–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ: 3 –ø–∏–∫–∞, —Å—Ä–µ–¥–Ω–∏–π –≤—ã—à–µ –¥—Ä—É–≥–∏—Ö
        peaks = []
        for i in range(5, len(highs) - 5):
            if highs[i] > highs[i-5:i].max() and highs[i] > highs[i+1:i+6].max():
                peaks.append((i, highs[i]))
        
        if len(peaks) >= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ä–µ–¥–Ω–∏–π –ø–∏–∫ –≤—ã—à–µ
            if len(peaks) >= 3:
                if peaks[1][1] > peaks[0][1] and peaks[1][1] > peaks[2][1]:
                    return {
                        'signal': 'SELL',
                        'confidence': 0.65,
                        'description': 'Head and Shoulders detected (bearish)'
                    }
        
        return None
    
    def _detect_double_top(self, df: pd.DataFrame) -> Optional[Dict]:
        """–î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞ (bearish pattern)"""
        if len(df) < 30:
            return None
        
        highs = df['high'].values[-30:]
        
        # –ù–∞–π—Ç–∏ –¥–≤–∞ –±–ª–∏–∑–∫–∏—Ö –ø–∏–∫–∞
        peaks = []
        for i in range(3, len(highs) - 3):
            if highs[i] > highs[i-3:i].max() and highs[i] > highs[i+1:i+4].max():
                peaks.append((i, highs[i]))
        
        if len(peaks) >= 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–≤–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–∏–∫–∞ –±–ª–∏–∑–∫–∏ –ø–æ –≤—ã—Å–æ—Ç–µ
            last_two = peaks[-2:]
            diff_pct = abs(last_two[0][1] - last_two[1][1]) / last_two[0][1]
            
            if diff_pct < 0.02:  # 2% —Ä–∞–∑–Ω–∏—Ü–∞
                return {
                    'signal': 'SELL',
                    'confidence': 0.60,
                    'description': 'Double Top detected (bearish)'
                }
        
        return None
    
    def _detect_double_bottom(self, df: pd.DataFrame) -> Optional[Dict]:
        """–î–≤–æ–π–Ω–æ–µ –¥–Ω–æ (bullish pattern)"""
        if len(df) < 30:
            return None
        
        lows = df['low'].values[-30:]
        
        # –ù–∞–π—Ç–∏ –¥–≤–∞ –±–ª–∏–∑–∫–∏—Ö –º–∏–Ω–∏–º—É–º–∞
        bottoms = []
        for i in range(3, len(lows) - 3):
            if lows[i] < lows[i-3:i].min() and lows[i] < lows[i+1:i+4].min():
                bottoms.append((i, lows[i]))
        
        if len(bottoms) >= 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–≤–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –º–∏–Ω–∏–º—É–º–∞ –±–ª–∏–∑–∫–∏
            last_two = bottoms[-2:]
            diff_pct = abs(last_two[0][1] - last_two[1][1]) / last_two[0][1]
            
            if diff_pct < 0.02:  # 2% —Ä–∞–∑–Ω–∏—Ü–∞
                return {
                    'signal': 'BUY',
                    'confidence': 0.60,
                    'description': 'Double Bottom detected (bullish)'
                }
        
        return None
    
    def _detect_ascending_triangle(self, df: pd.DataFrame) -> Optional[Dict]:
        """–í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ (bullish pattern)"""
        if len(df) < 20:
            return None
        
        highs = df['high'].values[-20:]
        lows = df['low'].values[-20:]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: highs –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ, lows —Ä–∞—Å—Ç—É—Ç
        highs_std = np.std(highs[-10:]) / np.mean(highs[-10:])
        lows_trend = np.polyfit(range(len(lows[-10:])), lows[-10:], 1)[0]
        
        if highs_std < 0.02 and lows_trend > 0:
            return {
                'signal': 'BUY',
                'confidence': 0.55,
                'description': 'Ascending Triangle detected (bullish)'
            }
        
        return None
    
    def _detect_descending_triangle(self, df: pd.DataFrame) -> Optional[Dict]:
        """–ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ (bearish pattern)"""
        if len(df) < 20:
            return None
        
        highs = df['high'].values[-20:]
        lows = df['low'].values[-20:]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: lows –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ, highs –ø–∞–¥–∞—é—Ç
        lows_std = np.std(lows[-10:]) / np.mean(lows[-10:])
        highs_trend = np.polyfit(range(len(highs[-10:])), highs[-10:], 1)[0]
        
        if lows_std < 0.02 and highs_trend < 0:
            return {
                'signal': 'SELL',
                'confidence': 0.55,
                'description': 'Descending Triangle detected (bearish)'
            }
        
        return None
    
    def _detect_support_resistance_breakout(self, df: pd.DataFrame) -> Optional[Dict]:
        """–ü—Ä–æ–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è"""
        if len(df) < 50:
            return None
        
        closes = df['close'].values
        volumes = df['volume'].values
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å–≤–µ—á–µ–π
        recent_closes = closes[-50:]
        recent_volumes = volumes[-50:]
        
        # –ù–∞–π—Ç–∏ —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
        resistance = np.percentile(recent_closes[:-5], 95)
        support = np.percentile(recent_closes[:-5], 5)
        
        current_price = closes[-1]
        avg_volume = np.mean(recent_volumes[:-5])
        current_volume = volumes[-1]
        
        # –ü—Ä–æ–±–æ–π —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è (bullish)
        if current_price > resistance and current_volume > avg_volume * 1.5:
            return {
                'signal': 'BUY',
                'confidence': 0.70,
                'description': f'Resistance breakout at {resistance:.2f} with high volume'
            }
        
        # –ü—Ä–æ–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (bearish)
        if current_price < support and current_volume > avg_volume * 1.5:
            return {
                'signal': 'SELL',
                'confidence': 0.70,
                'description': f'Support breakdown at {support:.2f} with high volume'
            }
        
        return None


class IntelligentAI:
    """
    Intelligent AI - Multi-Model Ensemble
    
    –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç:
    1. LSTM –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã
    2. Pattern Recognition –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    3. Ensemble voting –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    """
    
    def __init__(self, model_dir: str = "models"):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        
        # LSTM model
        self.lstm_model = None
        self.lstm_scaler = MinMaxScaler()  # For features
        self.price_scaler = MinMaxScaler()  # For price (target)
        self.sequence_length = 60  # 60 —Å–≤–µ—á–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        
        # Pattern recognizer
        self.pattern_recognizer = PatternRecognizer()
        
        # Ensemble weights
        self.weights = {
            'lstm': 0.40,       # 40% - LSTM prediction
            'patterns': 0.30,   # 30% - Pattern recognition
            'technical': 0.30   # 30% - Technical indicators
        }
        
        # Model state
        self.is_trained = False
        self.last_prediction = None
        self.last_prediction_time = None
        
        logger.info("ü§ñ IntelligentAI initialized")
    
    def prepare_lstm_data(self, df: pd.DataFrame, prediction_horizon: int = 1) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è LSTM
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏
            prediction_horizon: –ù–∞ —Å–∫–æ–ª—å–∫–æ —Å–≤–µ—á–µ–π –≤–ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å
            
        Returns:
            (X, y) - features –∏ labels
        """
        # Features: OHLCV + technical indicators
        features = []
        
        # Basic OHLCV
        features.append(df['open'].values)
        features.append(df['high'].values)
        features.append(df['low'].values)
        features.append(df['close'].values)
        features.append(df['volume'].values)
        
        # Technical indicators
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        features.append(rsi.fillna(50).values)
        
        # Moving averages
        ma_7 = df['close'].rolling(window=7).mean()
        ma_25 = df['close'].rolling(window=25).mean()
        features.append(ma_7.bfill().values)
        features.append(ma_25.bfill().values)
        
        # MACD
        ema_12 = df['close'].ewm(span=12).mean()
        ema_26 = df['close'].ewm(span=26).mean()
        macd = ema_12 - ema_26
        features.append(macd.fillna(0).values)
        
        # Combine features
        features = np.column_stack(features)
        
        # Create sequences
        X, y = [], []
        
        for i in range(self.sequence_length, len(features) - prediction_horizon):
            X.append(features[i - self.sequence_length:i])
            # Predict next close price
            y.append(df['close'].iloc[i + prediction_horizon])
        
        return np.array(X), np.array(y)
    
    def train_lstm(self, df: pd.DataFrame, epochs: int = 50, batch_size: int = 32) -> Dict:
        """
        –û–±—É—á–∏—Ç—å LSTM –º–æ–¥–µ–ª—å
        
        Args:
            df: DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            
        Returns:
            Dictionary —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        if len(df) < self.sequence_length + 100:
            return {'error': 'Not enough data for training'}
        
        logger.info(f"Training LSTM model on {len(df)} samples...")
        
        # Prepare data
        X, y = self.prepare_lstm_data(df)
        
        if len(X) == 0:
            return {'error': 'Failed to prepare data'}
        
        # Scale features (X)
        X_reshaped = X.reshape(-1, X.shape[-1])
        X_scaled = self.lstm_scaler.fit_transform(X_reshaped)
        X_scaled = X_scaled.reshape(X.shape)
        
        # Scale targets (y) - prices
        y_scaled = self.price_scaler.fit_transform(y.reshape(-1, 1)).flatten()
        
        # Train/test split
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]
        y_train, y_test = y_scaled[:split_idx], y_scaled[split_idx:]
        
        # Create datasets
        train_dataset = TimeSeriesDataset(X_train, y_train)
        test_dataset = TimeSeriesDataset(X_test, y_test)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        # Initialize model
        input_size = X.shape[2]
        self.lstm_model = LSTMPricePredictor(input_size=input_size)
        
        # Loss and optimizer
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.lstm_model.parameters(), lr=0.001)
        
        # Training loop
        train_losses = []
        test_losses = []
        
        for epoch in range(epochs):
            # Train
            self.lstm_model.train()
            epoch_loss = 0
            
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = self.lstm_model(batch_X)
                loss = criterion(outputs.squeeze(), batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            avg_train_loss = epoch_loss / len(train_loader)
            train_losses.append(avg_train_loss)
            
            # Test
            self.lstm_model.eval()
            test_loss = 0
            
            with torch.no_grad():
                for batch_X, batch_y in test_loader:
                    outputs = self.lstm_model(batch_X)
                    loss = criterion(outputs.squeeze(), batch_y)
                    test_loss += loss.item()
            
            avg_test_loss = test_loss / len(test_loader)
            test_losses.append(avg_test_loss)
            
            if (epoch + 1) % 10 == 0:
                logger.info(f"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.6f}, Test Loss: {avg_test_loss:.6f}")
        
        # Save model
        model_path = self.model_dir / "lstm_model.pth"
        torch.save(self.lstm_model.state_dict(), model_path)
        
        # Save scalers
        scaler_path = self.model_dir / "lstm_scaler.pkl"
        with open(scaler_path, 'wb') as f:
            pickle.dump(self.lstm_scaler, f)
        
        price_scaler_path = self.model_dir / "price_scaler.pkl"
        with open(price_scaler_path, 'wb') as f:
            pickle.dump(self.price_scaler, f)
        
        self.is_trained = True
        
        logger.info(f"‚úÖ LSTM model trained and saved to {model_path}")
        
        return {
            'epochs': epochs,
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'final_train_loss': train_losses[-1],
            'final_test_loss': test_losses[-1],
            'model_path': str(model_path)
        }
    
    def load_lstm_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é LSTM –º–æ–¥–µ–ª—å"""
        model_path = self.model_dir / "lstm_model.pth"
        scaler_path = self.model_dir / "lstm_scaler.pkl"
        price_scaler_path = self.model_dir / "price_scaler.pkl"
        
        if not model_path.exists() or not scaler_path.exists() or not price_scaler_path.exists():
            logger.warning("LSTM model not found. Train first.")
            return False
        
        try:
            # Load scalers
            with open(scaler_path, 'rb') as f:
                self.lstm_scaler = pickle.load(f)
            
            with open(price_scaler_path, 'rb') as f:
                self.price_scaler = pickle.load(f)
            
            # Initialize model (we need to know input_size)
            # For now, use default 9 features
            self.lstm_model = LSTMPricePredictor(input_size=9)
            self.lstm_model.load_state_dict(torch.load(model_path))
            self.lstm_model.eval()
            
            self.is_trained = True
            logger.info("‚úÖ LSTM model loaded")
            return True
        
        except Exception as e:
            logger.error(f"Failed to load LSTM model: {e}")
            return False
    
    def predict_lstm(self, df: pd.DataFrame) -> Optional[float]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ü–µ–Ω—É —Å –ø–æ–º–æ—â—å—é LSTM
        
        Args:
            df: DataFrame —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            Predicted price or None
        """
        if self.lstm_model is None:
            if not self.load_lstm_model():
                return None
        
        if len(df) < self.sequence_length:
            logger.warning(f"Not enough data for prediction (need {self.sequence_length}, got {len(df)})")
            return None
        
        try:
            # Prepare features
            X, _ = self.prepare_lstm_data(df)
            
            if len(X) == 0:
                return None
            
            # Take last sequence
            last_sequence = X[-1:]
            
            # Scale
            last_sequence_reshaped = last_sequence.reshape(-1, last_sequence.shape[-1])
            last_sequence_scaled = self.lstm_scaler.transform(last_sequence_reshaped)
            last_sequence_scaled = last_sequence_scaled.reshape(last_sequence.shape)
            
            # Predict
            self.lstm_model.eval()
            with torch.no_grad():
                input_tensor = torch.FloatTensor(last_sequence_scaled)
                prediction = self.lstm_model(input_tensor)
                predicted_price_scaled = prediction.item()
            
            # Denormalize prediction
            predicted_price = self.price_scaler.inverse_transform([[predicted_price_scaled]])[0][0]
            
            return predicted_price
        
        except Exception as e:
            logger.error(f"LSTM prediction error: {e}")
            return None
    
    def get_ensemble_prediction(self, df: pd.DataFrame) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            Dictionary —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Å–∏–≥–Ω–∞–ª–æ–º
        """
        current_price = df['close'].iloc[-1]
        predictions = {}
        
        # 1. LSTM Prediction
        lstm_price = self.predict_lstm(df)
        if lstm_price:
            lstm_signal = 'BUY' if lstm_price > current_price else 'SELL'
            lstm_confidence = abs(lstm_price - current_price) / current_price
            
            predictions['lstm'] = {
                'signal': lstm_signal,
                'predicted_price': lstm_price,
                'current_price': current_price,
                'change_pct': ((lstm_price - current_price) / current_price) * 100,
                'confidence': min(lstm_confidence * 10, 1.0),  # Scale to 0-1
                'weight': self.weights['lstm']
            }
        
        # 2. Pattern Recognition
        patterns = self.pattern_recognizer.detect_patterns(df)
        if patterns and 'error' not in patterns:
            # Aggregate pattern signals
            pattern_signals = []
            pattern_confidences = []
            
            for pattern_name, pattern_data in patterns.items():
                if isinstance(pattern_data, dict) and 'signal' in pattern_data:
                    pattern_signals.append(pattern_data['signal'])
                    pattern_confidences.append(pattern_data['confidence'])
            
            if pattern_signals:
                # Majority voting
                buy_count = pattern_signals.count('BUY')
                sell_count = pattern_signals.count('SELL')
                
                if buy_count > sell_count:
                    pattern_signal = 'BUY'
                elif sell_count > buy_count:
                    pattern_signal = 'SELL'
                else:
                    pattern_signal = 'NEUTRAL'
                
                avg_confidence = np.mean(pattern_confidences)
                
                predictions['patterns'] = {
                    'signal': pattern_signal,
                    'patterns_detected': len(pattern_signals),
                    'buy_count': buy_count,
                    'sell_count': sell_count,
                    'confidence': avg_confidence,
                    'weight': self.weights['patterns'],
                    'details': patterns
                }
        
        # 3. Technical Indicators (simple)
        tech_signal, tech_confidence = self._get_technical_signal(df)
        predictions['technical'] = {
            'signal': tech_signal,
            'confidence': tech_confidence,
            'weight': self.weights['technical']
        }
        
        # Ensemble Voting
        final_signal, final_confidence = self._ensemble_vote(predictions)
        
        result = {
            'timestamp': datetime.now(),
            'current_price': current_price,
            'final_signal': final_signal,
            'final_confidence': final_confidence,
            'predictions': predictions
        }
        
        self.last_prediction = result
        self.last_prediction_time = datetime.now()
        
        return result
    
    def _get_technical_signal(self, df: pd.DataFrame) -> Tuple[str, float]:
        """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        if len(df) < 26:
            return 'NEUTRAL', 0.5
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        current_rsi = rsi.iloc[-1]
        
        # MACD
        ema_12 = df['close'].ewm(span=12).mean()
        ema_26 = df['close'].ewm(span=26).mean()
        macd = ema_12 - ema_26
        signal_line = macd.ewm(span=9).mean()
        
        current_macd = macd.iloc[-1]
        current_signal = signal_line.iloc[-1]
        
        # Voting
        signals = []
        
        # RSI signal
        if current_rsi < 30:
            signals.append('BUY')
        elif current_rsi > 70:
            signals.append('SELL')
        else:
            signals.append('NEUTRAL')
        
        # MACD signal
        if current_macd > current_signal:
            signals.append('BUY')
        elif current_macd < current_signal:
            signals.append('SELL')
        else:
            signals.append('NEUTRAL')
        
        # Aggregate
        buy_count = signals.count('BUY')
        sell_count = signals.count('SELL')
        
        if buy_count > sell_count:
            return 'BUY', 0.6
        elif sell_count > buy_count:
            return 'SELL', 0.6
        else:
            return 'NEUTRAL', 0.5
    
    def _ensemble_vote(self, predictions: Dict) -> Tuple[str, float]:
        """
        –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏
        
        Args:
            predictions: Dict —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            
        Returns:
            (final_signal, confidence)
        """
        weighted_votes = {'BUY': 0, 'SELL': 0, 'NEUTRAL': 0}
        
        for model_name, pred in predictions.items():
            signal = pred['signal']
            weight = pred['weight']
            confidence = pred.get('confidence', 0.5)
            
            # Weighted vote
            weighted_votes[signal] += weight * confidence
        
        # Find winner
        max_vote = max(weighted_votes.values())
        
        if max_vote == 0:
            return 'NEUTRAL', 0.5
        
        winner = max(weighted_votes, key=weighted_votes.get)
        
        # Calculate final confidence
        total_votes = sum(weighted_votes.values())
        final_confidence = weighted_votes[winner] / total_votes if total_votes > 0 else 0.5
        
        # Map to PredictionSignal
        if winner == 'BUY':
            if final_confidence > 0.8:
                return PredictionSignal.STRONG_BUY.value, final_confidence
            else:
                return PredictionSignal.BUY.value, final_confidence
        elif winner == 'SELL':
            if final_confidence > 0.8:
                return PredictionSignal.STRONG_SELL.value, final_confidence
            else:
                return PredictionSignal.SELL.value, final_confidence
        else:
            return PredictionSignal.NEUTRAL.value, final_confidence
    
    def get_status(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å AI –º–æ–¥—É–ª—è"""
        return {
            'lstm_trained': self.is_trained,
            'last_prediction': self.last_prediction_time.isoformat() if self.last_prediction_time else None,
            'model_weights': self.weights,
            'sequence_length': self.sequence_length
        }


# Example usage
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("IntelligentAI Module - Phase 7")
    print("=" * 70)
    
    # This is just a placeholder
    # Real testing will be done with actual market data
    print("\n‚úÖ Module created successfully")
    print("   - LSTM Price Predictor")
    print("   - Pattern Recognition")
    print("   - Ensemble Voting")
